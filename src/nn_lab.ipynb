{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import itertools\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import getopt\n",
    "import sys\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "import data_manager\n",
    "\n",
    "from data_manager import PytorchDataset, w2v_matrix_vocab_generator\n",
    "from models import lstm, gru, rnn, lstm2ch, encoder, attention, conv, fcinit, lstmcrf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_init(*args):\n",
    "    \"\"\"\n",
    "    Init functions for data loader workers.\n",
    "    :param args:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    random.seed(1337)\n",
    "    np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data_to_predict):\n",
    "    \"\"\"\n",
    "    Use the model to predict on data.\n",
    "    :param model: The nn module (or equivalent, implementing zero_grad() and being callable).\n",
    "    :param data_to_predict: PytorchDataset containing data.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    y_predicted = []\n",
    "\n",
    "    dataloader = DataLoader(data_to_predict, 1, shuffle=False, num_workers=1, drop_last=False, pin_memory=True,\n",
    "                            collate_fn=lambda x: x, worker_init_fn=worker_init)\n",
    "    for batch in dataloader:\n",
    "        current = []\n",
    "\n",
    "        # predict and check error\n",
    "        predicted, _ = model(batch)\n",
    "\n",
    "        # needed because other models return a score for each possible tag class\n",
    "        if not isinstance(model, lstmcrf.LstmCrf):\n",
    "            predicted = torch.argmax(predicted, dim=1)\n",
    "\n",
    "        for i in predicted:\n",
    "            current.append(i.item())\n",
    "        y_predicted.append(current)\n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_predictions(tokens, labels, predictions, path, is_indexes, class_dict):\n",
    "    \"\"\"\n",
    "    Write predictions to file, 1 word per line format.\n",
    "    :param tokens: Word tokens of sentences, a list of lists (a list of sentences).\n",
    "    :param labels: Concepts/labels of sentences, a list of lists, if is_indexes is True these must be\n",
    "    concept indices instead of strings, to be mapped back to string with the class_dict.\n",
    "    :param predictions: Indexes representing classes, a list of lists, mapped back to concepts (strings) with class_dict.\n",
    "    :param path: where to save the predictions.\n",
    "    \"\"\"\n",
    "    index_to_class = {v: k for k, v in class_dict.items()}\n",
    "    with open(path, \"w\") as file:\n",
    "        for tokens_seq, labels_seq, predictions_seq in zip(tokens, labels, predictions):\n",
    "            for word, concept, predicted_concept in zip(tokens_seq, labels_seq, predictions_seq):\n",
    "                conc = index_to_class[concept] if is_indexes else concept\n",
    "                file.write(\"%s %s %s\\n\" % (word, conc, index_to_class[predicted_concept]))\n",
    "            file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(dev_data, model, class_dict, batch_size, mode=\"dev\"):\n",
    "    \"\"\"\n",
    "    Test a model on data and print the error, precision, recall and f1 score.\n",
    "\n",
    "    :param dev_data: Data on which to train.\n",
    "    :param model: The nn module (or equivalent, implementing zero_grad() and being callable).\n",
    "    :param class_dict: Dict mapping indices to concepts.\n",
    "    :param batch_size: Size of the training batch.\n",
    "    \"\"\"\n",
    "    error = []\n",
    "    y_predicted = []\n",
    "    y_true = []\n",
    "\n",
    "    dataloader = DataLoader(dev_data, batch_size, shuffle=False, num_workers=1, drop_last=False, pin_memory=True,\n",
    "                            collate_fn=lambda x: x, worker_init_fn=worker_init)\n",
    "\n",
    "    for batch in dataloader:\n",
    "\n",
    "        # predict and check error\n",
    "        predicted, labels = model(batch)\n",
    "\n",
    "        # needed because other models return a score for each possible tag class\n",
    "        if not isinstance(model, lstmcrf.LstmCrf):\n",
    "            loss = torch.nn.functional.nll_loss(predicted, labels, ignore_index=-1)\n",
    "            # update current epoch dev_data\n",
    "            error.append(loss.item())\n",
    "            predicted = torch.argmax(predicted, dim=1)\n",
    "\n",
    "        # add labels and predictions to list\n",
    "        tmp_pred = []\n",
    "        tmp_true = []\n",
    "        for index, label in zip(predicted, labels):\n",
    "            ival = index.item()\n",
    "            labelval = label.item()\n",
    "            if labelval != -1:\n",
    "                tmp_pred.append(ival)\n",
    "                tmp_true.append(labelval)\n",
    "            else:\n",
    "                y_predicted.append(tmp_pred)\n",
    "                y_true.append(tmp_true)\n",
    "                tmp_pred, tmp_true = [], []\n",
    "\n",
    "    if not isinstance(model, lstmcrf.LstmCrf):\n",
    "        print(mode + \" error: %f\" % np.mean(error))\n",
    "\n",
    "    # evaluate by calling the evaluation script then clean up\n",
    "    print(mode + \" stats:\")\n",
    "    write_predictions(y_true, y_true, y_predicted, \"../output/dev_pred.txt\", True, class_dict)\n",
    "    print(subprocess.check_output(\"../output/conlleval.pl < ../output/dev_pred.txt | head -n2\", shell=True).decode(\"utf-8\"))\n",
    "    os.system(\"rm ../output/dev_pred.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_data, model, class_dict, dev_data, batch_size, lr, epochs, decay=0.0):\n",
    "    \"\"\"\n",
    "    Trains a model and prints error, precision, recall and f1 while doing so, if dev data is passed\n",
    "    the model is going to be evaluated on it every epoch.\n",
    "    :param train_data: Data on which to train.\n",
    "    :param model: The nn module (or equivalent, implementing zero_grad() and being callable).\n",
    "    :param class_dict: Dict mapping indices to concepts.\n",
    "    :param dev_data: Dev data on which to evaluate, if this is passed the function will also print f1 and error for both\n",
    "    train and dev data.\n",
    "    :param batch_size: Size of the training batch.\n",
    "    :param lr: Learning rate.\n",
    "    :param epochs: Epochs on the data set.\n",
    "    :param decay: L2 norm decay to be used, default is 0.\n",
    "    \"\"\"\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, amsgrad=True,\n",
    "                                 weight_decay=decay)\n",
    "    # to adjust the lr\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2)\n",
    "\n",
    "    starting_time = time.time()\n",
    "\n",
    "    dataloader = DataLoader(train_data, batch_size, shuffle=True, num_workers=1, drop_last=False, pin_memory=True,\n",
    "                            collate_fn=lambda x: x, worker_init_fn=worker_init)\n",
    "    \"\"\"for x in model.parameters():\n",
    "        if x.requires_grad:\n",
    "            print(x.name, x.shape)\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # setup current epoch train_data\n",
    "        error = []\n",
    "        y_predicted = []\n",
    "        y_true = []\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        # train\n",
    "        model.zero_grad()\n",
    "        for batch in dataloader:\n",
    "\n",
    "            # predict and check err\n",
    "            if isinstance(model, lstmcrf.LstmCrf):\n",
    "                loss = model.neg_log_likelihood(batch)\n",
    "            else:\n",
    "                predicted, labels = model(batch)\n",
    "                loss = torch.nn.functional.nll_loss(predicted, labels, ignore_index=-1)\n",
    "                indices = torch.argmax(predicted, dim=1)\n",
    "\n",
    "                # add labels and predictions to list\n",
    "                tmp_pred = []\n",
    "                tmp_true = []\n",
    "                for index, label in zip(indices, labels):\n",
    "                    ival = index.item()\n",
    "                    labelval = label.item()\n",
    "                    if labelval != -1:\n",
    "                        tmp_pred.append(ival)\n",
    "                        tmp_true.append(labelval)\n",
    "                    else:\n",
    "                        y_predicted.append(tmp_pred)\n",
    "                        y_true.append(tmp_true)\n",
    "                        tmp_pred, tmp_true = [], []\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "            # update current epoch train_data\n",
    "            error.append(loss.item())\n",
    "\n",
    "        scheduler.step(np.mean(error))\n",
    "\n",
    "        print(\"----- Training epoch stats for epoch %i -----\" % epoch)\n",
    "        print(\"Seconds for epoch: % f\" % (time.time() - start))\n",
    "\n",
    "        print(\"Train error: %f\" % np.mean(error))\n",
    "        if not isinstance(model, lstmcrf.LstmCrf):\n",
    "            print(\"Train stats:\")\n",
    "            # evaluate by calling the evaluation script then clean up\n",
    "            write_predictions(y_true, y_true, y_predicted, \"../output/train_pred.txt\", True,\n",
    "                              class_dict)\n",
    "            print(subprocess.check_output(\"../output/conlleval.pl < ../output/train_pred.txt | head -n2\", shell=True).decode(\"utf-8\"))\n",
    "            os.system(\"rm ../output/train_pred.txt\")\n",
    "\n",
    "        # if we passed dev train_data to it evaluate on it and report, else keep training\n",
    "        if dev_data is not None:\n",
    "            model.eval()\n",
    "            evaluate_model(dev_data, model, class_dict, batch_size)\n",
    "            model.train()\n",
    "\n",
    "    print(\"total time\")\n",
    "    print(time.time() - starting_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_class_dict(train_df, test_df, column=\"concepts\"):\n",
    "    \"\"\"\n",
    "    Given the train and test dataframe, containing \"concepts\" columns, where every entry is a list of strings representing\n",
    "    the concepts or classes we are trying to predict, return a dictionary mapping a concept to a index.\n",
    "    :param train_df: Train dataframe, must contain the \"concepts\" column.\n",
    "    :param test_df: Test dataframe, must contain the \"concepts\" column.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    class_dict = dict()\n",
    "    # make a set of concepts by merging the sets obtained by concepts from train and test dataframes\n",
    "    concepts = set(itertools.chain(*train_df[column].values)) | set(itertools.chain(*test_df[column].values))\n",
    "    # add to dict and return\n",
    "    for concept in sorted(concepts):\n",
    "        class_dict[concept] = len(class_dict)\n",
    "    return class_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_and_transformers(params, class_dict):\n",
    "    \"\"\"\n",
    "    Pick and construct the model and the init and drop transformers given the params, the init transformer\n",
    "    makes it so that the data in the PytorchDataset is in the tensors of shape and sizes needed, the drop transformer\n",
    "    randomly drops tokens at run time when a sample is returned from the dataset, to simulate unknown words.\n",
    "    Also deals with selecting the right device and putting the model on that device, GPU is preferred if available.\n",
    "    :return: model, data transformer at dataset initialization, data transformer at run time\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    w2v_vocab, w2v_weights = w2v_matrix_vocab_generator(params[\"w2v\"])\n",
    "    #print(w2v_weights.shape)\n",
    "    c2v_vocab = None\n",
    "    c2v_weights = None\n",
    "\n",
    "    if params[\"c2v\"] is not None:\n",
    "        c2v_vocab, c2v_weights = w2v_matrix_vocab_generator(params[\"c2v\"])\n",
    "\n",
    "    init_data_transform = data_manager.InitTransform(w2v_vocab, class_dict, c2v_vocab)\n",
    "    drop_data_transform = data_manager.DropTransform(0.001, w2v_vocab[\"<UNK>\"], w2v_vocab[\"<padding>\"])\n",
    "\n",
    "    # needed for some models, given their architecture, i.e. CONV\n",
    "    padded_sentence_length = 50\n",
    "    # needed by models when using c2v embeddings\n",
    "    padded_word_length = 30\n",
    "    if params[\"model\"] == \"lstm\":\n",
    "        model = lstm.LSTM(device, w2v_weights, params[\"hidden_size\"], len(class_dict),\n",
    "                          params[\"drop\"],\n",
    "                          params[\"bidirectional\"], not params[\"unfreeze\"], params[\"embedding_norm\"],\n",
    "                          c2v_weights, padded_word_length)\n",
    "    elif params[\"model\"] == \"gru\":\n",
    "        model = gru.GRU(device, w2v_weights, params[\"hidden_size\"], len(class_dict),\n",
    "                        params[\"drop\"],\n",
    "                        params[\"bidirectional\"], not params[\"unfreeze\"], params[\"embedding_norm\"],\n",
    "                        c2v_weights, padded_word_length)\n",
    "    elif params[\"model\"] == \"rnn\":\n",
    "        model = rnn.RNN(device, w2v_weights, params[\"hidden_size\"], len(class_dict),\n",
    "                        params[\"drop\"],\n",
    "                        params[\"bidirectional\"], not params[\"unfreeze\"], params[\"embedding_norm\"],\n",
    "                        c2v_weights, padded_word_length)\n",
    "    elif params[\"model\"] == \"lstm2ch\":\n",
    "        model = lstm2ch.LSTM2CH(device, w2v_weights, params[\"hidden_size\"], len(class_dict), params[\"drop\"],\n",
    "                                params[\"bidirectional\"], params[\"embedding_norm\"])\n",
    "    elif params[\"model\"] == \"encoder\":\n",
    "        tag_embedding_size = 20\n",
    "        model = encoder.EncoderDecoderRNN(device, w2v_weights, tag_embedding_size, params[\"hidden_size\"],\n",
    "                                          len(class_dict), params[\"drop\"], params[\"bidirectional\"],\n",
    "                                          not params[\"unfreeze\"], params[\"embedding_norm\"],\n",
    "                                          params[\"embedding_norm\"])\n",
    "    elif params[\"model\"] == \"attention\":\n",
    "        tag_embedding_size = 20\n",
    "        model = attention.Attention(device, w2v_weights, tag_embedding_size, params[\"hidden_size\"],\n",
    "                                    len(class_dict), params[\"drop\"], params[\"bidirectional\"], not params[\"unfreeze\"],\n",
    "                                    params[\"embedding_norm\"], params[\"embedding_norm\"],\n",
    "                                    padded_sentence_length=padded_sentence_length)\n",
    "    elif params[\"model\"] == \"conv\":\n",
    "        model = conv.CONV(device, w2v_weights, params[\"hidden_size\"], len(class_dict), padded_sentence_length,\n",
    "                          params[\"drop\"], params[\"bidirectional\"], not params[\"unfreeze\"],\n",
    "                          params[\"embedding_norm\"])\n",
    "    elif params[\"model\"] == \"fcinit\":\n",
    "        model = fcinit.FCINIT(device, w2v_weights, params[\"hidden_size\"], len(class_dict), padded_sentence_length,\n",
    "                              params[\"drop\"], params[\"bidirectional\"], not params[\"unfreeze\"], params[\"embedding_norm\"])\n",
    "    elif params[\"model\"] == \"lstmcrf\":\n",
    "        model = lstmcrf.LstmCrf(device, w2v_weights, class_dict, params[\"hidden_size\"], params[\"drop\"],\n",
    "                                params[\"bidirectional\"], not params[\"unfreeze\"], params[\"embedding_norm\"], c2v_weights,\n",
    "                                padded_word_length)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"total trainable parameters %i\" % params)\n",
    "    return model, init_data_transform, drop_data_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1337)\n",
    "np.random.seed(1337)\n",
    "params = dict()\n",
    "params[\"train\"] = \"../data/movies/train.pickle\"\n",
    "params[\"test\"] = \"../data/movies/test.pickle\"\n",
    "params[\"dev\"] = \"../data/movies/dev.pickle\"\n",
    "params[\"w2v\"] = \"../data/movies/w2v_trimmed.pickle\"\n",
    "# Play with the following parameters\n",
    "params[\"model\"] = \"rnn\" # architectures: \"lstm\", \"rnn\", \"gru\", \"lstm2ch\", \"encoder\", \"attention\", \"conv\", \"fcinit\", \"lstmcrf\"\n",
    "params[\"bidirectional\"] = False\n",
    "params[\"unfreeze\"] = False\n",
    "params[\"lr\"] = 0.001\n",
    "params[\"batch\"] = 50\n",
    "params[\"drop\"] = 0.3\n",
    "params[\"epochs\"] = 15\n",
    "params[\"hidden_size\"] = 200\n",
    "params[\"save_model\"] = \"rnn_model\"\n",
    "params[\"write_results\"] = \"rnn_out\"\n",
    "# ignore the rest of the parameters for now\n",
    "params[\"c2v\"] = None\n",
    "params[\"embedding_norm\"] = 4\n",
    "params[\"decay\"] = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "total trainable parameters 109045\n",
      "training in dev mode\n",
      "----- Training epoch stats for epoch 0 -----\n",
      "Seconds for epoch:  7.808839\n",
      "Train error: 1.023409\n",
      "Train stats:\n",
      "processed 21453 tokens with 3265 phrases; found: 3687 phrases; correct: 806.\n",
      "accuracy:  76.33%; precision:  21.86%; recall:  24.69%; FB1:  23.19\n",
      "\n",
      "dev error: 0.439811\n",
      "dev stats:\n",
      "processed 4253 tokens with 653 phrases; found: 681 phrases; correct: 336.\n",
      "accuracy:  88.48%; precision:  49.34%; recall:  51.45%; FB1:  50.37\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-358c175bb501>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training in dev mode\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     train_model(train_data, model, class_dict, dev_data, params[\"batch\"], params[\"lr\"], params[\"epochs\"],\n\u001b[0;32m---> 19\u001b[0;31m                 params[\"decay\"])\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-106-e05c7a378d54>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_data, model, class_dict, dev_data, batch_size, lr, epochs, decay)\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/LUS/concept-tagging-with-neural-networks/src/models/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched_conv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mrec_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurrent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;31m# send output to fc layer(s)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mtag_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden2tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 179\u001b[0;31m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# load data\n",
    "print(\"loading data\")\n",
    "train_df = pd.read_pickle(params[\"train\"])\n",
    "dev_df = pd.read_pickle(params[\"dev\"])\n",
    "test_df = pd.read_pickle(params[\"test\"])\n",
    "#print(train_df.iloc[0,:])\n",
    "class_dict = generate_class_dict(train_df, test_df)\n",
    "#print(class_dict)\n",
    "# build model and data transformers based on arguments\n",
    "model, init_data_transform, run_data_transform = generate_model_and_transformers(params, class_dict)\n",
    "\n",
    "train_data = PytorchDataset(train_df, init_data_transform, run_data_transform)\n",
    "dev_data = PytorchDataset(dev_df, init_data_transform)\n",
    "test_data = PytorchDataset(test_df, init_data_transform)  # notice that there is no run_data_transform for test & dev data\n",
    "if params[\"dev\"]:\n",
    "    print(\"training in dev mode\")\n",
    "    train_model(train_data, model, class_dict, dev_data, params[\"batch\"], params[\"lr\"], params[\"epochs\"],\n",
    "                params[\"decay\"])\n",
    "else:\n",
    "    print(\"training\")\n",
    "    train_model(train_data, model, class_dict, None, params[\"batch\"], params[\"lr\"], params[\"epochs\"],\n",
    "                params[\"decay\"])\n",
    "print(\"=\"*50)\n",
    "print(\"testing\")\n",
    "model.eval()\n",
    "evaluate_model(test_data, model, class_dict, params[\"batch\"], \"test\")\n",
    "predictions = predict(model, test_data)\n",
    "if params[\"write_results\"] is not None:\n",
    "    write_predictions(test_df[\"tokens\"].values, test_df[\"concepts\"].values, predictions,\n",
    "                      params[\"write_results\"], False, class_dict)\n",
    "\n",
    "if params[\"save_model\"] is not None:\n",
    "    torch.save(model.state_dict(), params[\"save_model\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
