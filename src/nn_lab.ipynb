{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import itertools\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import getopt\n",
    "import sys\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "import data_manager\n",
    "\n",
    "from data_manager import PytorchDataset, w2v_matrix_vocab_generator\n",
    "from models import lstm, gru, rnn, lstm2ch, encoder, attention, conv, fcinit, lstmcrf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_init(*args):\n",
    "    \"\"\"\n",
    "    Init functions for data loader workers.\n",
    "    :param args:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    random.seed(1337)\n",
    "    np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data_to_predict):\n",
    "    \"\"\"\n",
    "    Use the model to predict on data.\n",
    "    :param model: The nn module (or equivalent, implementing zero_grad() and being callable).\n",
    "    :param data_to_predict: PytorchDataset containing data.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    y_predicted = []\n",
    "\n",
    "    dataloader = DataLoader(data_to_predict, 1, shuffle=False, num_workers=1, drop_last=False, pin_memory=True,\n",
    "                            collate_fn=lambda x: x, worker_init_fn=worker_init)\n",
    "    for batch in dataloader:\n",
    "        current = []\n",
    "\n",
    "        # predict and check error\n",
    "        predicted, _ = model(batch)\n",
    "\n",
    "        # needed because other models return a score for each possible tag class\n",
    "        if not isinstance(model, lstmcrf.LstmCrf):\n",
    "            predicted = torch.argmax(predicted, dim=1)\n",
    "\n",
    "        for i in predicted:\n",
    "            current.append(i.item())\n",
    "        y_predicted.append(current)\n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_predictions(tokens, labels, predictions, path, is_indexes, class_dict):\n",
    "    \"\"\"\n",
    "    Write predictions to file, 1 word per line format.\n",
    "    :param tokens: Word tokens of sentences, a list of lists (a list of sentences).\n",
    "    :param labels: Concepts/labels of sentences, a list of lists, if is_indexes is True these must be\n",
    "    concept indices instead of strings, to be mapped back to string with the class_dict.\n",
    "    :param predictions: Indexes representing classes, a list of lists, mapped back to concepts (strings) with class_dict.\n",
    "    :param path: where to save the predictions.\n",
    "    \"\"\"\n",
    "    index_to_class = {v: k for k, v in class_dict.items()}\n",
    "    with open(path, \"w\") as file:\n",
    "        for tokens_seq, labels_seq, predictions_seq in zip(tokens, labels, predictions):\n",
    "            for word, concept, predicted_concept in zip(tokens_seq, labels_seq, predictions_seq):\n",
    "                conc = index_to_class[concept] if is_indexes else concept\n",
    "                file.write(\"%s %s %s\\n\" % (word, conc, index_to_class[predicted_concept]))\n",
    "            file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(dev_data, model, class_dict, batch_size, mode=\"dev\"):\n",
    "    \"\"\"\n",
    "    Test a model on data and print the error, precision, recall and f1 score.\n",
    "\n",
    "    :param dev_data: Data on which to train.\n",
    "    :param model: The nn module (or equivalent, implementing zero_grad() and being callable).\n",
    "    :param class_dict: Dict mapping indices to concepts.\n",
    "    :param batch_size: Size of the training batch.\n",
    "    \"\"\"\n",
    "    error = []\n",
    "    y_predicted = []\n",
    "    y_true = []\n",
    "\n",
    "    dataloader = DataLoader(dev_data, batch_size, shuffle=False, num_workers=1, drop_last=False, pin_memory=True,\n",
    "                            collate_fn=lambda x: x, worker_init_fn=worker_init)\n",
    "\n",
    "    for batch in dataloader:\n",
    "\n",
    "        # predict and check error\n",
    "        predicted, labels = model(batch)\n",
    "\n",
    "        # needed because other models return a score for each possible tag class\n",
    "        if not isinstance(model, lstmcrf.LstmCrf):\n",
    "            loss = torch.nn.functional.nll_loss(predicted, labels, ignore_index=-1)\n",
    "            # update current epoch dev_data\n",
    "            error.append(loss.item())\n",
    "            predicted = torch.argmax(predicted, dim=1)\n",
    "\n",
    "        # add labels and predictions to list\n",
    "        tmp_pred = []\n",
    "        tmp_true = []\n",
    "        for index, label in zip(predicted, labels):\n",
    "            ival = index.item()\n",
    "            labelval = label.item()\n",
    "            if labelval != -1:\n",
    "                tmp_pred.append(ival)\n",
    "                tmp_true.append(labelval)\n",
    "            else:\n",
    "                y_predicted.append(tmp_pred)\n",
    "                y_true.append(tmp_true)\n",
    "                tmp_pred, tmp_true = [], []\n",
    "\n",
    "    if not isinstance(model, lstmcrf.LstmCrf):\n",
    "        print(mode + \" error: %f\" % np.mean(error))\n",
    "\n",
    "    # evaluate by calling the evaluation script then clean up\n",
    "    print(mode + \" stats:\")\n",
    "    write_predictions(y_true, y_true, y_predicted, \"../output/dev_pred.txt\", True, class_dict)\n",
    "    print(subprocess.check_output(\"../output/conlleval.pl < ../output/dev_pred.txt | head -n2\", shell=True).decode(\"utf-8\"))\n",
    "    os.system(\"rm ../output/dev_pred.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_data, model, class_dict, dev_data, batch_size, lr, epochs, decay=0.0):\n",
    "    \"\"\"\n",
    "    Trains a model and prints error, precision, recall and f1 while doing so, if dev data is passed\n",
    "    the model is going to be evaluated on it every epoch.\n",
    "    :param train_data: Data on which to train.\n",
    "    :param model: The nn module (or equivalent, implementing zero_grad() and being callable).\n",
    "    :param class_dict: Dict mapping indices to concepts.\n",
    "    :param dev_data: Dev data on which to evaluate, if this is passed the function will also print f1 and error for both\n",
    "    train and dev data.\n",
    "    :param batch_size: Size of the training batch.\n",
    "    :param lr: Learning rate.\n",
    "    :param epochs: Epochs on the data set.\n",
    "    :param decay: L2 norm decay to be used, default is 0.\n",
    "    \"\"\"\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, amsgrad=True,\n",
    "                                 weight_decay=decay)\n",
    "    # to adjust the lr\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2)\n",
    "\n",
    "    starting_time = time.time()\n",
    "\n",
    "    dataloader = DataLoader(train_data, batch_size, shuffle=True, num_workers=1, drop_last=False, pin_memory=True,\n",
    "                            collate_fn=lambda x: x, worker_init_fn=worker_init)\n",
    "    for x in model.parameters():\n",
    "        print(x.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # setup current epoch train_data\n",
    "        error = []\n",
    "        y_predicted = []\n",
    "        y_true = []\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        # train\n",
    "        model.zero_grad()\n",
    "        for batch in dataloader:\n",
    "\n",
    "            # predict and check err\n",
    "            if isinstance(model, lstmcrf.LstmCrf):\n",
    "                loss = model.neg_log_likelihood(batch)\n",
    "            else:\n",
    "                predicted, labels = model(batch)\n",
    "                loss = torch.nn.functional.nll_loss(predicted, labels, ignore_index=-1)\n",
    "                indices = torch.argmax(predicted, dim=1)\n",
    "\n",
    "                # add labels and predictions to list\n",
    "                tmp_pred = []\n",
    "                tmp_true = []\n",
    "                for index, label in zip(indices, labels):\n",
    "                    ival = index.item()\n",
    "                    labelval = label.item()\n",
    "                    if labelval != -1:\n",
    "                        tmp_pred.append(ival)\n",
    "                        tmp_true.append(labelval)\n",
    "                    else:\n",
    "                        y_predicted.append(tmp_pred)\n",
    "                        y_true.append(tmp_true)\n",
    "                        tmp_pred, tmp_true = [], []\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "            # update current epoch train_data\n",
    "            error.append(loss.item())\n",
    "\n",
    "        scheduler.step(np.mean(error))\n",
    "\n",
    "        print(\"----- Training epoch stats for epoch %i -----\" % epoch)\n",
    "        print(\"Seconds for epoch: % f\" % (time.time() - start))\n",
    "\n",
    "        print(\"Train error: %f\" % np.mean(error))\n",
    "        if not isinstance(model, lstmcrf.LstmCrf):\n",
    "            print(\"Train stats:\")\n",
    "            # evaluate by calling the evaluation script then clean up\n",
    "            write_predictions(y_true, y_true, y_predicted, \"../output/train_pred.txt\", True,\n",
    "                              class_dict)\n",
    "            print(subprocess.check_output(\"../output/conlleval.pl < ../output/train_pred.txt | head -n2\", shell=True).decode(\"utf-8\"))\n",
    "            os.system(\"rm ../output/train_pred.txt\")\n",
    "\n",
    "        # if we passed dev train_data to it evaluate on it and report, else keep training\n",
    "        if dev_data is not None:\n",
    "            model.eval()\n",
    "            evaluate_model(dev_data, model, class_dict, batch_size)\n",
    "            model.train()\n",
    "\n",
    "    print(\"total time\")\n",
    "    print(time.time() - starting_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_class_dict(train_df, test_df, column=\"concepts\"):\n",
    "    \"\"\"\n",
    "    Given the train and test dataframe, containing \"concepts\" columns, where every entry is a list of strings representing\n",
    "    the concepts or classes we are trying to predict, return a dictionary mapping a concept to a index.\n",
    "    :param train_df: Train dataframe, must contain the \"concepts\" column.\n",
    "    :param test_df: Test dataframe, must contain the \"concepts\" column.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    class_dict = dict()\n",
    "    # make a set of concepts by merging the sets obtained by concepts from train and test dataframes\n",
    "    concepts = set(itertools.chain(*train_df[column].values)) | set(itertools.chain(*test_df[column].values))\n",
    "    # add to dict and return\n",
    "    for concept in sorted(concepts):\n",
    "        class_dict[concept] = len(class_dict)\n",
    "    return class_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_and_transformers(params, class_dict):\n",
    "    \"\"\"\n",
    "    Pick and construct the model and the init and drop transformers given the params, the init transformer\n",
    "    makes it so that the data in the PytorchDataset is in the tensors of shape and sizes needed, the drop transformer\n",
    "    randomly drops tokens at run time when a sample is returned from the dataset, to simulate unknown words.\n",
    "    Also deals with selecting the right device and putting the model on that device, GPU is preferred if available.\n",
    "    :return: model, data transformer at dataset initialization, data transformer at run time\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    w2v_vocab, w2v_weights = w2v_matrix_vocab_generator(params[\"w2v\"])\n",
    "    print(w2v_weights.shape)\n",
    "    c2v_vocab = None\n",
    "    c2v_weights = None\n",
    "\n",
    "    if params[\"c2v\"] is not None:\n",
    "        c2v_vocab, c2v_weights = w2v_matrix_vocab_generator(params[\"c2v\"])\n",
    "\n",
    "    init_data_transform = data_manager.InitTransform(w2v_vocab, class_dict, c2v_vocab)\n",
    "    drop_data_transform = data_manager.DropTransform(0.001, w2v_vocab[\"<UNK>\"], w2v_vocab[\"<padding>\"])\n",
    "\n",
    "    # needed for some models, given their architecture, i.e. CONV\n",
    "    padded_sentence_length = 50\n",
    "    # needed by models when using c2v embeddings\n",
    "    padded_word_length = 30\n",
    "    if params[\"model\"] == \"lstm\":\n",
    "        model = lstm.LSTM(device, w2v_weights, params[\"hidden_size\"], len(class_dict),\n",
    "                          params[\"drop\"],\n",
    "                          params[\"bidirectional\"], not params[\"unfreeze\"], params[\"embedding_norm\"],\n",
    "                          c2v_weights, padded_word_length)\n",
    "    elif params[\"model\"] == \"gru\":\n",
    "        model = gru.GRU(device, w2v_weights, params[\"hidden_size\"], len(class_dict),\n",
    "                        params[\"drop\"],\n",
    "                        params[\"bidirectional\"], not params[\"unfreeze\"], params[\"embedding_norm\"],\n",
    "                        c2v_weights, padded_word_length)\n",
    "    elif params[\"model\"] == \"rnn\":\n",
    "        model = rnn.RNN(device, w2v_weights, params[\"hidden_size\"], len(class_dict),\n",
    "                        params[\"drop\"],\n",
    "                        params[\"bidirectional\"], not params[\"unfreeze\"], params[\"embedding_norm\"],\n",
    "                        c2v_weights, padded_word_length)\n",
    "    elif params[\"model\"] == \"lstm2ch\":\n",
    "        model = lstm2ch.LSTM2CH(device, w2v_weights, params[\"hidden_size\"], len(class_dict), params[\"drop\"],\n",
    "                                params[\"bidirectional\"], params[\"embedding_norm\"])\n",
    "    elif params[\"model\"] == \"encoder\":\n",
    "        tag_embedding_size = 20\n",
    "        model = encoder.EncoderDecoderRNN(device, w2v_weights, tag_embedding_size, params[\"hidden_size\"],\n",
    "                                          len(class_dict), params[\"drop\"], params[\"bidirectional\"],\n",
    "                                          not params[\"unfreeze\"], params[\"embedding_norm\"],\n",
    "                                          params[\"embedding_norm\"])\n",
    "    elif params[\"model\"] == \"attention\":\n",
    "        tag_embedding_size = 20\n",
    "        model = attention.Attention(device, w2v_weights, tag_embedding_size, params[\"hidden_size\"],\n",
    "                                    len(class_dict), params[\"drop\"], params[\"bidirectional\"], not params[\"unfreeze\"],\n",
    "                                    params[\"embedding_norm\"], params[\"embedding_norm\"],\n",
    "                                    padded_sentence_length=padded_sentence_length)\n",
    "    elif params[\"model\"] == \"conv\":\n",
    "        model = conv.CONV(device, w2v_weights, params[\"hidden_size\"], len(class_dict), padded_sentence_length,\n",
    "                          params[\"drop\"], params[\"bidirectional\"], not params[\"unfreeze\"],\n",
    "                          params[\"embedding_norm\"])\n",
    "    elif params[\"model\"] == \"fcinit\":\n",
    "        model = fcinit.FCINIT(device, w2v_weights, params[\"hidden_size\"], len(class_dict), padded_sentence_length,\n",
    "                              params[\"drop\"], params[\"bidirectional\"], not params[\"unfreeze\"], params[\"embedding_norm\"])\n",
    "    elif params[\"model\"] == \"lstmcrf\":\n",
    "        model = lstmcrf.LstmCrf(device, w2v_weights, class_dict, params[\"hidden_size\"], params[\"drop\"],\n",
    "                                params[\"bidirectional\"], not params[\"unfreeze\"], params[\"embedding_norm\"], c2v_weights,\n",
    "                                padded_word_length)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    print(\"total trainable parameters %i\" % params)\n",
    "    return model, init_data_transform, drop_data_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1337)\n",
    "np.random.seed(1337)\n",
    "params = dict()\n",
    "params[\"train\"] = \"../data/movies/train.pickle\"\n",
    "params[\"test\"] = \"../data/movies/test.pickle\"\n",
    "params[\"dev\"] = \"../data/movies/dev.pickle\"\n",
    "params[\"w2v\"] = \"../data/movies/w2v_trimmed.pickle\"\n",
    "# Play with the following parameters\n",
    "params[\"model\"] = \"rnn\" # architectures: \"lstm\", \"rnn\", \"gru\", \"lstm2ch\", \"encoder\", \"attention\", \"conv\", \"fcinit\", \"lstmcrf\"\n",
    "params[\"bidirectional\"] = True\n",
    "params[\"unfreeze\"] = True\n",
    "params[\"lr\"] = 0.001\n",
    "params[\"batch\"] = 50\n",
    "params[\"drop\"] = 0.3\n",
    "params[\"epochs\"] = 15\n",
    "params[\"hidden_size\"] = 200\n",
    "params[\"save_model\"] = \"rnn_model\"\n",
    "params[\"write_results\"] = \"rnn_out\"\n",
    "# ignore the rest of the parameters for now\n",
    "params[\"c2v\"] = None\n",
    "params[\"embedding_norm\"] = 4\n",
    "params[\"decay\"] = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "tokens          [who, plays, luke, on, star, wars, new, hope]\n",
      "lemmas            [who, play, luke, on, star, war, new, hope]\n",
      "pos                        [WP, VVZ, NN, IN, NN, NNS, JJ, NN]\n",
      "concepts    [O, O, B-character.name, O, B-movie.name, I-mo...\n",
      "combined    [whowhoWP, playsplayVVZ, lukelukeNN, ononIN, s...\n",
      "Name: 0, dtype: object\n",
      "{'B-actor.name': 0, 'B-actor.nationality': 1, 'B-actor.type': 2, 'B-award.category': 3, 'B-award.ceremony': 4, 'B-character.name': 5, 'B-country.name': 6, 'B-director.name': 7, 'B-director.nationality': 8, 'B-movie.description': 9, 'B-movie.genre': 10, 'B-movie.gross_revenue': 11, 'B-movie.language': 12, 'B-movie.location': 13, 'B-movie.name': 14, 'B-movie.release_date': 15, 'B-movie.release_region': 16, 'B-movie.star_rating': 17, 'B-movie.subject': 18, 'B-movie.type': 19, 'B-person.name': 20, 'B-person.nationality': 21, 'B-producer.name': 22, 'B-rating.name': 23, 'I-actor.name': 24, 'I-actor.nationality': 25, 'I-award.category': 26, 'I-award.ceremony': 27, 'I-character.name': 28, 'I-country.name': 29, 'I-director.name': 30, 'I-movie.genre': 31, 'I-movie.gross_revenue': 32, 'I-movie.language': 33, 'I-movie.location': 34, 'I-movie.name': 35, 'I-movie.release_date': 36, 'I-movie.release_region': 37, 'I-movie.subject': 38, 'I-person.name': 39, 'I-producer.name': 40, 'I-rating.name': 41, 'O': 42}\n",
      "(3917, 300)\n",
      "total trainable parameters 1264145\n",
      "training in dev mode\n",
      "torch.Size([3917, 300])\n",
      "torch.Size([100, 300])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 300])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([1])\n",
      "torch.Size([1])\n",
      "torch.Size([43, 200])\n",
      "torch.Size([43])\n",
      "----- Training epoch stats for epoch 0 -----\n",
      "Seconds for epoch:  9.221850\n",
      "Train error: 1.862518\n",
      "Train stats:\n",
      "processed 21453 tokens with 3265 phrases; found: 1422 phrases; correct: 63.\n",
      "accuracy:  69.49%; precision:   4.43%; recall:   1.93%; FB1:   2.69\n",
      "\n",
      "dev error: 0.901656\n",
      "dev stats:\n",
      "processed 4253 tokens with 653 phrases; found: 505 phrases; correct: 99.\n",
      "accuracy:  78.39%; precision:  19.60%; recall:  15.16%; FB1:  17.10\n",
      "\n",
      "----- Training epoch stats for epoch 1 -----\n",
      "Seconds for epoch:  9.330257\n",
      "Train error: 0.641626\n",
      "Train stats:\n",
      "processed 21453 tokens with 3265 phrases; found: 3292 phrases; correct: 1354.\n",
      "accuracy:  85.40%; precision:  41.13%; recall:  41.47%; FB1:  41.30\n",
      "\n",
      "dev error: 0.386855\n",
      "dev stats:\n",
      "processed 4253 tokens with 653 phrases; found: 674 phrases; correct: 417.\n",
      "accuracy:  91.18%; precision:  61.87%; recall:  63.86%; FB1:  62.85\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-cde8c279c9f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training in dev mode\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     train_model(train_data, model, class_dict, dev_data, params[\"batch\"], params[\"lr\"], params[\"epochs\"],\n\u001b[0;32m---> 19\u001b[0;31m                 params[\"decay\"])\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-88-b2e9e49e0268>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_data, model, class_dict, dev_data, batch_size, lr, epochs, decay)\u001b[0m\n\u001b[1;32m     62\u001b[0m                         \u001b[0mtmp_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# load data\n",
    "print(\"loading data\")\n",
    "train_df = pd.read_pickle(params[\"train\"])\n",
    "dev_df = pd.read_pickle(params[\"dev\"])\n",
    "test_df = pd.read_pickle(params[\"test\"])\n",
    "print(train_df.iloc[0,:])\n",
    "class_dict = generate_class_dict(train_df, test_df)\n",
    "print(class_dict)\n",
    "# build model and data transformers based on arguments\n",
    "model, init_data_transform, run_data_transform = generate_model_and_transformers(params, class_dict)\n",
    "\n",
    "train_data = PytorchDataset(train_df, init_data_transform, run_data_transform)\n",
    "dev_data = PytorchDataset(dev_df, init_data_transform)\n",
    "test_data = PytorchDataset(test_df, init_data_transform)  # notice that there is no run_data_transform for test & dev data\n",
    "if params[\"dev\"]:\n",
    "    print(\"training in dev mode\")\n",
    "    train_model(train_data, model, class_dict, dev_data, params[\"batch\"], params[\"lr\"], params[\"epochs\"],\n",
    "                params[\"decay\"])\n",
    "else:\n",
    "    print(\"training\")\n",
    "    train_model(train_data, model, class_dict, None, params[\"batch\"], params[\"lr\"], params[\"epochs\"],\n",
    "                params[\"decay\"])\n",
    "print(\"=\"*50)\n",
    "print(\"testing\")\n",
    "model.eval()\n",
    "evaluate_model(test_data, model, class_dict, params[\"batch\"], \"test\")\n",
    "predictions = predict(model, test_data)\n",
    "if params[\"write_results\"] is not None:\n",
    "    write_predictions(test_df[\"tokens\"].values, test_df[\"concepts\"].values, predictions,\n",
    "                      params[\"write_results\"], False, class_dict)\n",
    "\n",
    "if params[\"save_model\"] is not None:\n",
    "    torch.save(model.state_dict(), params[\"save_model\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
